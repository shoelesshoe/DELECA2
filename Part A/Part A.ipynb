{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40167f6a",
   "metadata": {},
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f2c4366-433d-4b9f-87e1-8294cfde9f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, BatchNormalization, Activation, ZeroPadding2D, LeakyReLU, ReLU, UpSampling2D, Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9770e538",
   "metadata": {},
   "source": [
    "# 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b9949ec-7611-4c6f-acbd-2ecc0553d856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99035</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99036</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99037</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99038</th>\n",
       "      <td>-1</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>...</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99039</th>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99040 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9    ...  775  776  777  \\\n",
       "0       23    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "1        7    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2       16    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3       15    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "4       23    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "99035   18    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "99036   24    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "99037   19    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "99038   -1  174  174  174  174  174  174  174  174  174  ...  174  174  174   \n",
       "99039   -1   42   42   42   42   42   42   42   42   42  ...   42   42   42   \n",
       "\n",
       "       778  779  780  781  782  783  784  \n",
       "0        0    0    0    0    0    0    0  \n",
       "1        0    0    0    0    0    0    0  \n",
       "2        0    0    0    0    0    0    0  \n",
       "3        0    0    0    0    0    0    0  \n",
       "4        0    0    0    0    0    0    0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  \n",
       "99035    0    0    0    0    0    0    0  \n",
       "99036    0    0    0    0    0    0    0  \n",
       "99037    0    0    0    0    0    0    0  \n",
       "99038  174  174  174  174  174  174  174  \n",
       "99039   42   42   42   42   42   42   42  \n",
       "\n",
       "[99040 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original = pd.read_csv('emnist-letters-train.csv', header=None)\n",
    "df_original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a24d2c",
   "metadata": {},
   "source": [
    "From the dataframe shown above, we can see that there are 785 different columns and 99040 different rows. After some analysis of the data in excel, we hypothesized that column 0 is the label column which identifies what alphabet the image would represent in its number-letter correspondence (with -1 representing a blank image) and the rest of the columns are pixel values. Hence for each row, we have 1 label value and 784 pixel values which can be nicely reshaped into a 28x28 image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8e2ddb",
   "metadata": {},
   "source": [
    "To confirm our hypothesis, we will do some data analysis of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f17198a",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Aanalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5f7bd6",
   "metadata": {},
   "source": [
    "Get all the labels in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f6df139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        23\n",
       "1         7\n",
       "2        16\n",
       "3        15\n",
       "4        23\n",
       "         ..\n",
       "99035    18\n",
       "99036    24\n",
       "99037    19\n",
       "99038    -1\n",
       "99039    -1\n",
       "Name: 0, Length: 99040, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabets = df_original.iloc[:, 0]\n",
    "alphabets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6357bdc",
   "metadata": {},
   "source": [
    "Get all the pixel values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba5e111d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99035</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99036</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99037</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99038</th>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>...</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99039</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99040 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1    2    3    4    5    6    7    8    9    10   ...  775  776  777  \\\n",
       "0        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "1        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "4        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "99035    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "99036    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "99037    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "99038  174  174  174  174  174  174  174  174  174  174  ...  174  174  174   \n",
       "99039   42   42   42   42   42   42   42   42   42   42  ...   42   42   42   \n",
       "\n",
       "       778  779  780  781  782  783  784  \n",
       "0        0    0    0    0    0    0    0  \n",
       "1        0    0    0    0    0    0    0  \n",
       "2        0    0    0    0    0    0    0  \n",
       "3        0    0    0    0    0    0    0  \n",
       "4        0    0    0    0    0    0    0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  \n",
       "99035    0    0    0    0    0    0    0  \n",
       "99036    0    0    0    0    0    0    0  \n",
       "99037    0    0    0    0    0    0    0  \n",
       "99038  174  174  174  174  174  174  174  \n",
       "99039   42   42   42   42   42   42   42  \n",
       "\n",
       "[99040 rows x 784 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_original.iloc[:, 1:]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557dd777",
   "metadata": {},
   "source": [
    "## y-label Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59581968",
   "metadata": {},
   "source": [
    "As we all know, there are 26 different alphabets in the English language. Hence we should have 26 different labels in the dataset if our hypothesis is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3058ef2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(alphabets.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73b62d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alphabets.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b714e6",
   "metadata": {},
   "source": [
    "However, we can see that there are actually 27 different unique labels in the dataset with the values ranging from 1 to 26 and -1. Let's try to find out what -1 represents and whether labels 1-26 are the alphabets' number-letter correspondence by plotting them out as images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe04b34",
   "metadata": {},
   "source": [
    "Before that, we need to do some data preprocessing to be able to plot out our images. As we can see from the datasets above, every row contains pixel values for every image in the form of a 1D array in as there are 784 columns which can be reshaped into a 28x28 array. We need to reshape them into 2D arrays to visualize them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09247caf",
   "metadata": {},
   "source": [
    "## Pixel Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64314f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest pixel value: 255\n",
      "Lowest pixel value: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'Highest pixel value: {df.max().max()}')\n",
    "print(f'Lowest pixel value: {df.min().min()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7676f3a2",
   "metadata": {},
   "source": [
    "The pixel values of the dataset ranges from 0 to 255 which confirms our hypothesis that the columns 1-785 are pixel values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2e6304",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c45bbfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMatrix(df):\n",
    "    \"\"\"\n",
    "    Gets the pixel value from each row and reshapes it into a 28x28 matrix\n",
    "    \"\"\"\n",
    "    arr = []\n",
    "\n",
    "    for row in range(len(df)):\n",
    "        img = df.iloc[row, :].values.reshape((28, 28))\n",
    "        arr.append(img)\n",
    "\n",
    "    arr = np.array(arr)\n",
    "    print(arr.shape)\n",
    "\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15096173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99040, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "imageArr = createMatrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e1a559",
   "metadata": {},
   "source": [
    "## Plot Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd00dd2d",
   "metadata": {},
   "source": [
    "Using plt.imshow(), we can visualise our transformed 2D arrays as grayscale images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f86dfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageSubplot(arr, numberOfImages, titles=None):\n",
    "    \"\"\"\n",
    "    Plots a 3 by `numberOfImages` grid of images\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "\n",
    "    for i in range(numberOfImages):\n",
    "        plt.subplot(numberOfImages // 3, 3, i+1)  \n",
    "        plt.imshow(arr[i], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        if titles:\n",
    "            plt.title(titles[i])\n",
    "        else:\n",
    "            plt.title(f'Image {i+1}')\n",
    "\n",
    "    plt.tight_layout()  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bd7279",
   "metadata": {},
   "source": [
    "### -1 Labelled Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b337063",
   "metadata": {},
   "source": [
    "Locate the indexes for the images labelled -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dcf46a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([   20,    30,    31,    36,    39,    41,    56,    65,    74,    75,\n",
       "       ...\n",
       "       98979, 99003, 99007, 99010, 99012, 99020, 99023, 99034, 99038, 99039],\n",
       "      dtype='int64', length=10240)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original[df_original.iloc[:, 0] == -1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ebb5b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "blankArr = [imageArr[20], imageArr[30], imageArr[31]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c3c6dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imageSubplot(blankArr, len(blankArr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33da91c",
   "metadata": {},
   "source": [
    "From the image plots above, we can see that the images labelled -1 are blank images. Hence we can conclude that -1 represents a blank image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d62839d",
   "metadata": {},
   "source": [
    "### Alphabet Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699343b9",
   "metadata": {},
   "source": [
    "Plot out first 6 images of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf0c9089",
   "metadata": {},
   "outputs": [],
   "source": [
    "first6labels = df_original.iloc[:6, 0].values\n",
    "first6alphabets = list(map(lambda x: f'{x}: {chr(x + 96)}', first6labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c2ad628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imageSubplot(imageArr, 6, first6alphabets)  # convert from number to alphabet and display them as subplot titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46794647",
   "metadata": {},
   "source": [
    "From the images above, we can see that the images labelled 1-26 are the number-letter correspondence of the English alphabets. Hence we can conclude that the labels 1-26 are the alphabets' number-letter correspondence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab13a509",
   "metadata": {},
   "source": [
    "However, we can see that our alphabets look slightly off. This is because the images are not in the correct orientation. We need to transpose them to the correct orientation (rotate 90 degrees clockwise + flip horizontally). We will do that by updating our createMatrix() function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6bdf2d",
   "metadata": {},
   "source": [
    "## Image Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "eb77490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMatrix(df):\n",
    "    \"\"\"\n",
    "    Gets the pixel value from each row and reshapes it into a 28x28 matrix and transposes it\n",
    "    \"\"\"\n",
    "    arr = []\n",
    "\n",
    "    for row in range(len(df)):\n",
    "        img = df.iloc[row, :].values.reshape((28, 28))\n",
    "        arr.append(np.transpose(img))\n",
    "\n",
    "    arr = np.array(arr)\n",
    "    print(arr.shape)\n",
    "\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "84c90ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99040, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "imageArr = createMatrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29182acf",
   "metadata": {},
   "source": [
    "Now let's visualise the transformed images and verify that they are in the correct orientation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8390b38a",
   "metadata": {},
   "source": [
    "### Blank Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3060b38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imageSubplot(blankArr, len(blankArr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3fe21a",
   "metadata": {},
   "source": [
    "### Alphabet Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "49c72feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imageSubplot(imageArr, 6, first6alphabets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e7d268",
   "metadata": {},
   "source": [
    "We have successfully verified that our transformation works and the images are now in the correct orientation. Our hypothesis about the first column being the labels and the rest of the columns being pixel values has been confirmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c38129",
   "metadata": {},
   "source": [
    "As our task is to generate images of the alphabets which do not include blank images, we should only focus on the images labelled 1-26 and ignore the blank images labelled -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98ce503",
   "metadata": {},
   "source": [
    "## Image Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "bd66a588",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, counts = np.unique(alphabets, return_counts=True)\n",
    "totalBlankImages = counts[np.where(labels == -1)]\n",
    "totalAlphabetImages = np.sum(counts[np.where(labels != -1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "f3d6ebf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1: 10240,\n",
       " 1: 3396,\n",
       " 2: 3396,\n",
       " 3: 3419,\n",
       " 4: 3398,\n",
       " 5: 3437,\n",
       " 6: 3394,\n",
       " 7: 3385,\n",
       " 8: 3424,\n",
       " 9: 3428,\n",
       " 10: 3402,\n",
       " 11: 3438,\n",
       " 12: 3415,\n",
       " 13: 3402,\n",
       " 14: 3365,\n",
       " 15: 3408,\n",
       " 16: 3430,\n",
       " 17: 3435,\n",
       " 18: 3419,\n",
       " 19: 3392,\n",
       " 20: 3436,\n",
       " 21: 3419,\n",
       " 22: 3422,\n",
       " 23: 3423,\n",
       " 24: 3437,\n",
       " 25: 3453,\n",
       " 26: 3427}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numberOfImages = {}\n",
    "for label, count in zip(labels, counts):\n",
    "    numberOfImages[label] = count\n",
    "numberOfImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "da74227f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='0', ylabel='count'>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=alphabets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9802c13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average difference between blank and alphabet images: 6951.111111111111\n"
     ]
    }
   ],
   "source": [
    "print(f'Average difference between blank and alphabet images: {(totalBlankImages - (totalAlphabetImages / len(counts)))[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8d2004",
   "metadata": {},
   "source": [
    "We can see that there is a huge difference (~7000 images) in the number of blank images compared to each the number of images for each alphabet. However, if we put into perspective the total number of alphabet images and the total number of blank images, will the difference still be significant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6ad911bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage: 11.53%\n"
     ]
    }
   ],
   "source": [
    "print(f'Percentage: {round((totalBlankImages / totalAlphabetImages * 100)[0], 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35db05f1",
   "metadata": {},
   "source": [
    "Since the total number of blank images is just above 10% of the whole dataset, we can safely ignore the blank images and focus on the alphabet images since generating alphabet images is our main task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9484f7d",
   "metadata": {},
   "source": [
    "## Alphabet Image Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d20447ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 3396,\n",
       " 2: 3396,\n",
       " 3: 3419,\n",
       " 4: 3398,\n",
       " 5: 3437,\n",
       " 6: 3394,\n",
       " 7: 3385,\n",
       " 8: 3424,\n",
       " 9: 3428,\n",
       " 10: 3402,\n",
       " 11: 3438,\n",
       " 12: 3415,\n",
       " 13: 3402,\n",
       " 14: 3365,\n",
       " 15: 3408,\n",
       " 16: 3430,\n",
       " 17: 3435,\n",
       " 18: 3419,\n",
       " 19: 3392,\n",
       " 20: 3436,\n",
       " 21: 3419,\n",
       " 22: 3422,\n",
       " 23: 3423,\n",
       " 24: 3437,\n",
       " 25: 3453,\n",
       " 26: 3427}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numberOfAlphabetImages = numberOfImages  # make a copy of the dictionary\n",
    "numberOfAlphabetImages.pop(-1)  # remove the blank image counts\n",
    "numberOfAlphabetImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36974d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='0', ylabel='count'>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=alphabets[alphabets != -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac77e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec120f17",
   "metadata": {},
   "source": [
    "### Alphabet 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43850028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imageSubplot(aArr, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d541c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81f209b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da6c4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe713054",
   "metadata": {},
   "source": [
    "## Excluding Images Without Alphabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "091fad11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99032</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99033</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99035</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99036</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99037</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88800 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1    2    3    4    5    6    7    8    9    10   ...  775  776  777  \\\n",
       "0        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "1        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "4        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "99032    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "99033    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "99035    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "99036    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "99037    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "\n",
       "       778  779  780  781  782  783  784  \n",
       "0        0    0    0    0    0    0    0  \n",
       "1        0    0    0    0    0    0    0  \n",
       "2        0    0    0    0    0    0    0  \n",
       "3        0    0    0    0    0    0    0  \n",
       "4        0    0    0    0    0    0    0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  \n",
       "99032    0    0    0    0    0    0    0  \n",
       "99033    0    0    0    0    0    0    0  \n",
       "99035    0    0    0    0    0    0    0  \n",
       "99036    0    0    0    0    0    0    0  \n",
       "99037    0    0    0    0    0    0    0  \n",
       "\n",
       "[88800 rows x 784 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_without_blank = df_original[df_original.iloc[:, 0] != -1].drop(0, axis=1)\n",
    "df_without_blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "03e19616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88800, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "withoutBlankArr = createMatrix(df_without_blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ad1f822b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88800, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "withoutBlankArr = createMatrix(df_without_blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeb98ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a13988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5324fa8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca0ecec7",
   "metadata": {},
   "source": [
    "# Model Training (With -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc1c81e",
   "metadata": {},
   "source": [
    "## Conv2DTranpose from Lab 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed969898",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN():\n",
    "    \n",
    "    # this is the function to build the generator neural network\n",
    "    def build_generator(self):\n",
    "        model = Sequential(name='Generator')\n",
    "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim)) # connect the input to dense layer\n",
    "        model.add(Reshape((7, 7, 128)))\n",
    "        # upsample from 7*7 to 14*14\n",
    "        model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        # upsample to 28x28\n",
    "        model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(self.channels, kernel_size=7, padding=\"same\", activation='sigmoid'))\n",
    "        model.summary()\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "        return Model(noise, img)  # the keras Model class groups layers into an object with training and inference features\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        model = Sequential(name='Discriminator')\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def __init__(self, rows, cols, channels, z = 100):\n",
    "        # Input shape\n",
    "        self.img_rows = rows  # generated image height\n",
    "        self.img_cols = cols  # generated image width\n",
    "        self.channels = channels  # generated image channel\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = z  # the input is 1-D vector of noise\n",
    "        # Reduce learning rate from 0.001 to 0.0002, and beta1 from 0.9 to 0.5, which can stablize training and reduce oscillation\n",
    "        optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "        # The generator takes noise as input and generates images\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "        # The combined model (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer)\n",
    "    \n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "        # Load the dataset\n",
    "        X_train = np.array(imageArr)\n",
    "        # Rescale 0 to 1\n",
    "        X_train = X_train / 255\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        for epoch in range(epochs):\n",
    "            # ---------------------\n",
    "            # Train Discriminator\n",
    "            # ---------------------\n",
    "            # Select a random half of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "            # Sample noise and generate a batch of new images\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            # Train the discriminator (it classify real images as 1 and generated images as 0)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            # Train the generator (it wants discriminator to predict generated images as 1)\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "            \n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch)\n",
    "    \n",
    "    def save_imgs(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        # gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        os.makedirs('generated_mnist', exist_ok=True)\n",
    "        fig.savefig(\"generated_mnist/dcgan_mnist_{:d}.png\".format(epoch))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e175a03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan = DCGAN(28,28,1)\n",
    "dcgan.train(epochs=5000, batch_size=256, save_interval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51edbf39",
   "metadata": {},
   "source": [
    "## Upsampling from Lab 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da4de4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN():\n",
    "    def __init__(self, rows, cols, channels, z = 10):\n",
    "        # Input shape\n",
    "        self.img_rows = rows\n",
    "        self.img_cols = cols\n",
    "        self.channels = channels\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = z\n",
    "\n",
    "        optimizer = Adam(0.0001, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((7, 7, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=256, save_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        X_train = np.array(imageArr)\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = X_train / 127.5 - 1.\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            # Sample noise and generate a batch of new images\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator (real classified as ones and generated as zeros)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Train the generator (wants discriminator to mistake images as real)\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch)\n",
    "\n",
    "    def save_imgs(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"dcgan_mnist_{:d}.png\".format(epoch))\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b70e91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan = DCGAN(28,28,1)\n",
    "dcgan.train(epochs=5000, batch_size=256, save_interval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8426fdb",
   "metadata": {},
   "source": [
    "## Editted Conv2DTranspose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1058edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN():\n",
    "    \n",
    "    # this is the function to build the generator neural network\n",
    "    def build_generator(self):\n",
    "        model = Sequential(name='Generator')\n",
    "        model.add(Dense(256 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((7, 7, 256)))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same'))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Conv2D(self.channels, kernel_size=7, padding=\"same\", activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "        return Model(noise, img)\n",
    "        \n",
    "    def build_discriminator(self):\n",
    "        model = Sequential(name='Discriminator')\n",
    "\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))  # Adjust dropout rate\n",
    "\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))  # Adjust dropout rate\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def __init__(self, rows, cols, channels, z = 100):\n",
    "        # Input shape\n",
    "        self.img_rows = rows  # generated image height\n",
    "        self.img_cols = cols  # generated image width\n",
    "        self.channels = channels  # generated image channel\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = z  # the input is 1-D vector of noise\n",
    "        # Reduce learning rate from 0.001 to 0.0002, and beta1 from 0.9 to 0.5, which can stablize training and reduce oscillation\n",
    "        optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "        # The generator takes noise as input and generates images\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "        # The combined model (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer)\n",
    "    \n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "        # Load the dataset\n",
    "        X_train = np.array(imageArr)\n",
    "        # Rescale 0 to 1\n",
    "        X_train = X_train / 255\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        for epoch in range(epochs):\n",
    "            # ---------------------\n",
    "            # Train Discriminator\n",
    "            # ---------------------\n",
    "            # Select a random half of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "            # Sample noise and generate a batch of new images\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            # Train the discriminator (it classify real images as 1 and generated images as 0)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            # Train the generator (it wants discriminator to predict generated images as 1)\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "            \n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch)\n",
    "    \n",
    "    def save_imgs(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        # gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        os.makedirs('generated_mnist', exist_ok=True)\n",
    "        fig.savefig(\"generated_mnist/dcgan_mnist_{:d}.png\".format(epoch))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3e7b3e",
   "metadata": {},
   "source": [
    "# Model Training (Without -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbec3cf2",
   "metadata": {},
   "source": [
    "## machinelearningmastery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3069e141",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN:\n",
    "    def __init__(self, rows, cols, channels, z=100):\n",
    "        # Input shape\n",
    "        self.img_rows = rows  # generated image height\n",
    "        self.img_cols = cols  # generated image width\n",
    "        self.channels = channels  # generated image channel\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = z  # the input is 1-D vector of noise\n",
    "        # Reduce learning rate from 0.001 to 0.0002, and beta1 from 0.9 to 0.5, which can stabilize training and reduce oscillation\n",
    "        disc_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "        gen_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "                                   optimizer=disc_optimizer,\n",
    "                                   metrics=['accuracy'])\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "        # The generator takes noise as input and generates images\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "        # The combined model (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy',\n",
    "                              optimizer=gen_optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "        model = Sequential(name='Generator')\n",
    "        model.add(Dense(256 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim)) # connect the input to dense layer\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "        model.add(Reshape((7, 7, 256)))\n",
    "        # upsample from 7*7 to 14*14\n",
    "        model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "        # upsample to 28x28\n",
    "        model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "        model.add(Conv2D(self.channels, (3,3), padding=\"same\", activation='tanh'))\n",
    "        model.summary()\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "        return Model(noise, img)  # the keras Model class groups layers into an object with training and inference features\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        model = Sequential(name='Discriminator')\n",
    "        # normal\n",
    "        model.add(Conv2D(128, (3,3), padding='same', input_shape=self.img_shape))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.4))\n",
    "        # downsample\n",
    "        model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.4))\n",
    "        # classifier\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "        # scale to [-1, 1]\n",
    "        X_train = withoutBlankArr / 127.5 - 1\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        # Lists to store the losses\n",
    "        d_losses = []\n",
    "        g_losses = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # ---------------------\n",
    "            # Train Discriminator\n",
    "            # ---------------------\n",
    "            # Select a random half of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "            # Sample noise and generate a batch of new images\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            # Train the discriminator (it classify real images as 1 and generated images as 0)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            d_losses.append(d_loss[0])  # Record the discriminator loss\n",
    "\n",
    "            # ---------------------\n",
    "            # Train Generator\n",
    "            # ---------------------\n",
    "            # Train the generator (it wants discriminator to predict generated images as 1)\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "            g_losses.append(g_loss)  # Record the generator loss\n",
    "\n",
    "            # Plot the progress\n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch)\n",
    "\n",
    "        # Plot loss curves\n",
    "        self.plot_loss(d_losses, g_losses)\n",
    "\n",
    "    def save_imgs(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        # gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        os.makedirs('generated_mnist', exist_ok=True)\n",
    "        fig.savefig(\"generated_mnist/dcgan_mnist_{:d}.png\".format(epoch))\n",
    "        plt.close()\n",
    "\n",
    "    def plot_loss(self, d_losses, g_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(d_losses, label='Discriminator Loss')\n",
    "        plt.plot(g_losses, label='Generator Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Loss Curves')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995b54e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan = DCGAN(28,28,1)\n",
    "dcgan.train(epochs=5000, batch_size=256, save_interval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78051de5",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2fefa7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_388 (Conv2D)         (None, 6, 6, 64)          640       \n",
      "                                                                 \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 6, 6, 64)          0         \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 6, 6, 64)          0         \n",
      "                                                                 \n",
      " conv2d_389 (Conv2D)         (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 3, 3, 128)         0         \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 3, 3, 128)         0         \n",
      "                                                                 \n",
      " conv2d_390 (Conv2D)         (None, 2, 2, 128)         147584    \n",
      "                                                                 \n",
      " leaky_re_lu_14 (LeakyReLU)  (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 222,593\n",
      "Trainable params: 222,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"Generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 12544)             1254400   \n",
      "                                                                 \n",
      " batch_normalization_396 (Ba  (None, 12544)            50176     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_20 (ReLU)             (None, 12544)             0         \n",
      "                                                                 \n",
      " reshape_4 (Reshape)         (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_20 (Conv2D  (None, 14, 14, 128)      32768     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_397 (Ba  (None, 14, 14, 128)      512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_21 (ReLU)             (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_21 (Conv2D  (None, 14, 14, 128)      147456    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_398 (Ba  (None, 14, 14, 128)      512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_22 (ReLU)             (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_22 (Conv2D  (None, 14, 14, 128)      147456    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_399 (Ba  (None, 14, 14, 128)      512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_23 (ReLU)             (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_23 (Conv2D  (None, 28, 28, 128)      409600    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_400 (Ba  (None, 28, 28, 128)      512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_24 (ReLU)             (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_24 (Conv2D  (None, 28, 28, 1)        1152      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,045,056\n",
      "Trainable params: 2,018,944\n",
      "Non-trainable params: 26,112\n",
      "_________________________________________________________________\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 1s 39ms/step\n",
      "8/8 [==============================] - 0s 35ms/step\n",
      "0 [D loss: 0.6898413598537445, acc.: 39.26%] [G loss: 0.6969302296638489] [FID: 14.01323942771186]\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 38ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "50 [D loss: 0.6892173588275909, acc.: 33.01%] [G loss: 0.5976380705833435] [FID: 10.729851834896646]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 39ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "100 [D loss: 0.6905370056629181, acc.: 40.62%] [G loss: 0.5652801990509033] [FID: 9.350990327702359]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 37ms/step\n",
      "8/8 [==============================] - 0s 35ms/step\n",
      "150 [D loss: 0.696030855178833, acc.: 46.68%] [G loss: 0.5419575572013855] [FID: 12.1644979348155]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 37ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "200 [D loss: 0.7128052413463593, acc.: 47.07%] [G loss: 0.5255443453788757] [FID: 21.311864932457826]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 37ms/step\n",
      "8/8 [==============================] - 0s 35ms/step\n",
      "250 [D loss: 0.7365243136882782, acc.: 47.46%] [G loss: 0.5278394222259521] [FID: 65.77250252744331]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 38ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "300 [D loss: 0.7500194311141968, acc.: 48.83%] [G loss: 0.5356301069259644] [FID: 88.432670035184]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 38ms/step\n",
      "8/8 [==============================] - 0s 35ms/step\n",
      "350 [D loss: 0.7549814283847809, acc.: 48.24%] [G loss: 0.5391063094139099] [FID: 105.9472061274294]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 38ms/step\n",
      "8/8 [==============================] - 0s 35ms/step\n",
      "400 [D loss: 0.7521811425685883, acc.: 48.05%] [G loss: 0.5537924766540527] [FID: 145.60537939141778]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 38ms/step\n",
      "450 [D loss: 0.7439495921134949, acc.: 47.27%] [G loss: 0.5680787563323975] [FID: 190.6916795020217]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 39ms/step\n",
      "8/8 [==============================] - 0s 38ms/step\n",
      "500 [D loss: 0.7358441054821014, acc.: 48.44%] [G loss: 0.580256998538971] [FID: 206.69979288204544]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 37ms/step\n",
      "550 [D loss: 0.7345328629016876, acc.: 49.02%] [G loss: 0.5859101414680481] [FID: 185.54477735239723]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 39ms/step\n",
      "600 [D loss: 0.7300291061401367, acc.: 48.83%] [G loss: 0.5934664011001587] [FID: 203.3250677865652]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 39ms/step\n",
      "8/8 [==============================] - 0s 35ms/step\n",
      "650 [D loss: 0.7177295982837677, acc.: 49.41%] [G loss: 0.6057562232017517] [FID: 197.7869062518398]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "700 [D loss: 0.7255015075206757, acc.: 48.44%] [G loss: 0.5949317812919617] [FID: 152.8435878407669]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 38ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "750 [D loss: 0.7192111611366272, acc.: 49.41%] [G loss: 0.6034749746322632] [FID: 180.7767418907614]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 39ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "800 [D loss: 0.7202550768852234, acc.: 49.02%] [G loss: 0.605726420879364] [FID: 153.36310722237067]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 41ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "850 [D loss: 0.7109021544456482, acc.: 48.44%] [G loss: 0.6188719272613525] [FID: 147.7753241314579]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 39ms/step\n",
      "8/8 [==============================] - 0s 35ms/step\n",
      "900 [D loss: 0.7112038135528564, acc.: 48.24%] [G loss: 0.6166191101074219] [FID: 202.9478527315859]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "950 [D loss: 0.7190501391887665, acc.: 48.83%] [G loss: 0.606951117515564] [FID: 161.29661491368046]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 41ms/step\n",
      "8/8 [==============================] - 0s 39ms/step\n",
      "1000 [D loss: 0.721270889043808, acc.: 48.24%] [G loss: 0.6045732498168945] [FID: 167.34230108065304]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 38ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "1050 [D loss: 0.7188840508460999, acc.: 48.63%] [G loss: 0.6079854369163513] [FID: 188.32828704420967]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 43ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "1100 [D loss: 0.7201072871685028, acc.: 48.83%] [G loss: 0.6111900806427002] [FID: 183.70870032178738]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 38ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "1150 [D loss: 0.7159701585769653, acc.: 48.05%] [G loss: 0.6128367185592651] [FID: 157.08699493472506]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 38ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "1200 [D loss: 0.7116234600543976, acc.: 48.63%] [G loss: 0.6236914396286011] [FID: 147.89821002428906]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20252\\2145597851.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReLU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2DTranspose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLeakyReLU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20252\\2145597851.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, epochs, batch_size, save_interval)\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[0mg_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Record the generator loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m             \u001b[1;31m# Calculate FID score at intervals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msave_interval\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minception_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_imgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m                 \u001b[0mfid_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{epoch} [D loss: {d_loss[0]}, acc.: {100 * d_loss[1]:.2f}%] [G loss: {g_loss}] [FID: {fid}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_imgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20252\\2145597851.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, model, real_images, generated_images)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcalculate_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerated_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;31m# Resize images to (299, 299) and convert grayscale to RGB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0mreal_images_resized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess_for_inception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[0mgenerated_images_resized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess_for_inception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;31m# Get the activations from the InceptionV3 model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mact_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_images_resized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20252\\2145597851.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, images)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mimages_rgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[1;31m# Convert grayscale to RGB by repeating the single channel three times\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0mimg_rgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m             \u001b[0mimg_resized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_rgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m299\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m299\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m             \u001b[0mimg_resized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_resized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[0mimages_rgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_resized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mimages_rgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages_rgb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\p2309248\\.conda\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\p2309248\\.conda\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1180\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1181\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\p2309248\\.conda\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(images, size, method, preserve_aspect_ratio, antialias, name)\u001b[0m\n\u001b[0;32m   1762\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mresize_with_scale_and_translate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1763\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1764\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Resize method is not implemented: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1766\u001b[1;33m   return _resize_images_common(\n\u001b[0m\u001b[0;32m   1767\u001b[0m       \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1768\u001b[0m       \u001b[0mresize_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1769\u001b[0m       \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\p2309248\\.conda\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(images, resizer_fn, size, preserve_aspect_ratio, name, skip_resize_if_same)\u001b[0m\n\u001b[0;32m   1503\u001b[0m     \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_height_const\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_width_const\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1505\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_batch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1506\u001b[0m       \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1507\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\p2309248\\.conda\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\p2309248\\.conda\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1180\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1181\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\p2309248\\.conda\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    557\u001b[0m                 \u001b[0m_call_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorator_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_qualified_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m                 instructions)\n\u001b[1;32m--> 561\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\p2309248\\.conda\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(input, axis, name, dim)\u001b[0m\n\u001b[0;32m    368\u001b[0m   \"\"\"\n\u001b[0;32m    369\u001b[0m   \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeprecation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeprecated_argument_lookup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"axis\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dim\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Must specify an axis argument to tf.expand_dims()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 372\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mexpand_dims_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\p2309248\\.conda\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\p2309248\\.conda\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1180\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1181\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\p2309248\\.conda\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(input, axis, name)\u001b[0m\n\u001b[0;32m    438\u001b[0m   \u001b[0mRaises\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mspecified\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[0mInvalidArgumentError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mout\u001b[0m \u001b[0mof\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m]\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m   \"\"\"\n\u001b[1;32m--> 442\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\p2309248\\.conda\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(input, axis, name)\u001b[0m\n\u001b[0;32m   2346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2347\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2348\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2349\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2350\u001b[1;33m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2351\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2352\u001b[0m       return expand_dims_eager_fallback(\n\u001b[0;32m   2353\u001b[0m           input, axis, name=name, ctx=_ctx)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, ReLU, Reshape, Conv2DTranspose, Conv2D, LeakyReLU, Dropout, Flatten, Input\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.linalg import sqrtm\n",
    "import tensorflow as tf\n",
    "\n",
    "class DCGAN:\n",
    "    def __init__(self, rows, cols, channels, z=100):\n",
    "        # Input shape\n",
    "        self.img_rows = rows\n",
    "        self.img_cols = cols\n",
    "        self.channels = channels\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = z\n",
    "        disc_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "        gen_optimizer = Adam(learning_rate=0.0001, beta_1=0.5)\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "                                   optimizer=disc_optimizer,\n",
    "                                   metrics=['accuracy'])\n",
    "        self.generator = self.build_generator()\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "        self.discriminator.trainable = False\n",
    "        valid = self.discriminator(img)\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy',\n",
    "                              optimizer=gen_optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "        model = Sequential(name='Generator')\n",
    "        model.add(Dense(7*7*256, use_bias=False, input_dim=self.latent_dim))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "        model.add(Reshape((7, 7, 256)))\n",
    "\n",
    "        model.add(Conv2DTranspose(128, (1, 1), strides=(2, 2), padding='same', use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "\n",
    "        model.add(Conv2DTranspose(128, (3, 3), strides=(1, 1), padding='same', use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "\n",
    "        model.add(Conv2DTranspose(128, (3, 3), strides=(1, 1), padding='same', use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "\n",
    "        model.add(Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "\n",
    "        model.add(Conv2DTranspose(1, (3, 3), strides=(1, 1), padding='same', use_bias=False, activation='tanh'))\n",
    "        model.summary()\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        model = Sequential(name='Discriminator')\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=5, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        \n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def preprocess_for_inception(self, images):\n",
    "        images_rgb = []\n",
    "        for img in images:\n",
    "            # Convert grayscale to RGB by repeating the single channel three times\n",
    "            img_rgb = np.repeat(img, 3, axis=-1)\n",
    "            img_resized = tf.image.resize(img_rgb, (299, 299))\n",
    "            img_resized = img_to_array(img_resized)\n",
    "            images_rgb.append(img_resized)\n",
    "        images_rgb = np.array(images_rgb)\n",
    "        return preprocess_input(images_rgb)\n",
    "\n",
    "    def calculate_fid(self, model, real_images, generated_images):\n",
    "        # Resize images to (299, 299) and convert grayscale to RGB\n",
    "        real_images_resized = self.preprocess_for_inception(real_images)\n",
    "        generated_images_resized = self.preprocess_for_inception(generated_images)\n",
    "        # Get the activations from the InceptionV3 model\n",
    "        act_real = model.predict(real_images_resized)\n",
    "        act_gen = model.predict(generated_images_resized)\n",
    "        # Calculate the mean and covariance of the activations\n",
    "        mu_real, sigma_real = act_real.mean(axis=0), np.cov(act_real, rowvar=False)\n",
    "        mu_gen, sigma_gen = act_gen.mean(axis=0), np.cov(act_gen, rowvar=False)\n",
    "        # Calculate the sum of squared differences between means\n",
    "        ssdiff = np.sum((mu_real - mu_gen) ** 2.0)\n",
    "        # Calculate the square root of the product of the covariances\n",
    "        covmean = sqrtm(sigma_real.dot(sigma_gen))\n",
    "        # Handle imaginary numbers\n",
    "        if np.iscomplexobj(covmean):\n",
    "            covmean = covmean.real\n",
    "        # Calculate the FID score\n",
    "        fid = ssdiff + np.trace(sigma_real + sigma_gen - 2.0 * covmean)\n",
    "        return fid\n",
    "\n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "        inception_model = InceptionV3(include_top=False, pooling='avg', input_shape=(299, 299, 3))\n",
    "\n",
    "        # scale to [-1, 1]\n",
    "        X_train = (withoutBlankArr - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        # Lists to store the losses and FID scores\n",
    "        d_losses = []\n",
    "        g_losses = []\n",
    "        fid_scores = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # ---------------------\n",
    "            # Train Discriminator\n",
    "            # ---------------------\n",
    "            # Select a random half of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "            # Sample noise and generate a batch of new images\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            # Train the discriminator (it classify real images as 1 and generated images as 0)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            d_losses.append(d_loss[0])  # Record the discriminator loss\n",
    "\n",
    "            # ---------------------\n",
    "            # Train Generator\n",
    "            # ---------------------\n",
    "            # Train the generator (it wants discriminator to predict generated images as 1)\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "            g_losses.append(g_loss)  # Record the generator loss\n",
    "\n",
    "            # Calculate FID score at intervals\n",
    "            if epoch % save_interval == 0:\n",
    "                fid = self.calculate_fid(inception_model, imgs, gen_imgs)\n",
    "                fid_scores.append(fid)\n",
    "                print(f\"{epoch} [D loss: {d_loss[0]}, acc.: {100 * d_loss[1]:.2f}%] [G loss: {g_loss}] [FID: {fid}]\")\n",
    "                self.save_imgs(epoch)\n",
    "\n",
    "        # Plot loss curves and FID scores\n",
    "        self.plot_loss(d_losses, g_losses, fid_scores)\n",
    "\n",
    "    def save_imgs(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        if not os.path.exists('images'):\n",
    "            os.makedirs('images')\n",
    "        fig.savefig(f\"images/mnist_{epoch}.png\")\n",
    "        plt.close()\n",
    "\n",
    "    def plot_loss(self, d_losses, g_losses, fid_scores):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(d_losses, label=\"Discriminator loss\")\n",
    "        plt.plot(g_losses, label=\"Generator loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot([i*50 for i in range(len(fid_scores))], fid_scores, label=\"FID score\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"FID score\")\n",
    "        plt.legend()\n",
    "\n",
    "        if not os.path.exists('plots'):\n",
    "            os.makedirs('plots')\n",
    "        plt.savefig(\"plots/loss_fid.png\")\n",
    "        plt.show()\n",
    "\n",
    "# Ensure your training dataset withoutBlankArr is properly loaded here\n",
    "\n",
    "dcgan = DCGAN(28, 28, 1)\n",
    "dcgan.train(epochs=10001, batch_size=256, save_interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f96c04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.19 ('gpu_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "5b460c8134041a9eb7f811dfdfca680bf522aea7d6535220209a5df6379dc02a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
