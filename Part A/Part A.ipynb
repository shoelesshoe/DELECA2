{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40167f6a",
   "metadata": {},
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f2c4366-433d-4b9f-87e1-8294cfde9f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, BatchNormalization, Activation, ZeroPadding2D, LeakyReLU, ReLU, UpSampling2D, Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9770e538",
   "metadata": {},
   "source": [
    "# 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b9949ec-7611-4c6f-acbd-2ecc0553d856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99035</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99036</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99037</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99038</th>\n",
       "      <td>-1</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>...</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99039</th>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99040 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9    ...  775  776  777  \\\n",
       "0       23    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "1        7    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2       16    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3       15    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "4       23    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "99035   18    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "99036   24    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "99037   19    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "99038   -1  174  174  174  174  174  174  174  174  174  ...  174  174  174   \n",
       "99039   -1   42   42   42   42   42   42   42   42   42  ...   42   42   42   \n",
       "\n",
       "       778  779  780  781  782  783  784  \n",
       "0        0    0    0    0    0    0    0  \n",
       "1        0    0    0    0    0    0    0  \n",
       "2        0    0    0    0    0    0    0  \n",
       "3        0    0    0    0    0    0    0  \n",
       "4        0    0    0    0    0    0    0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  \n",
       "99035    0    0    0    0    0    0    0  \n",
       "99036    0    0    0    0    0    0    0  \n",
       "99037    0    0    0    0    0    0    0  \n",
       "99038  174  174  174  174  174  174  174  \n",
       "99039   42   42   42   42   42   42   42  \n",
       "\n",
       "[99040 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original = pd.read_csv('emnist-letters-train.csv', header=None)\n",
    "df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfe9f85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        23\n",
       "1         7\n",
       "2        16\n",
       "3        15\n",
       "4        23\n",
       "         ..\n",
       "99035    18\n",
       "99036    24\n",
       "99037    19\n",
       "99038    -1\n",
       "99039    -1\n",
       "Name: 0, Length: 99040, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabets = df_original.iloc[:, 0]\n",
    "alphabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a680a9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99035</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99036</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99037</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99038</th>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>...</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99039</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99040 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1    2    3    4    5    6    7    8    9    10   ...  775  776  777  \\\n",
       "0        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "1        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "4        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "99035    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "99036    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "99037    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "99038  174  174  174  174  174  174  174  174  174  174  ...  174  174  174   \n",
       "99039   42   42   42   42   42   42   42   42   42   42  ...   42   42   42   \n",
       "\n",
       "       778  779  780  781  782  783  784  \n",
       "0        0    0    0    0    0    0    0  \n",
       "1        0    0    0    0    0    0    0  \n",
       "2        0    0    0    0    0    0    0  \n",
       "3        0    0    0    0    0    0    0  \n",
       "4        0    0    0    0    0    0    0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  \n",
       "99035    0    0    0    0    0    0    0  \n",
       "99036    0    0    0    0    0    0    0  \n",
       "99037    0    0    0    0    0    0    0  \n",
       "99038  174  174  174  174  174  174  174  \n",
       "99039   42   42   42   42   42   42   42  \n",
       "\n",
       "[99040 rows x 784 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_original.drop(0, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6511bf02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98945</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98959</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98982</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99021</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3396 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1    2    3    4    5    6    7    8    9    10   ...  775  776  777  \\\n",
       "164      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "184      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "216      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "220      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "226      0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "98945    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "98959    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "98982    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "98996    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "99021    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "\n",
       "       778  779  780  781  782  783  784  \n",
       "164      0    0    0    0    0    0    0  \n",
       "184      0    0    0    0    0    0    0  \n",
       "216      0    0    0    0    0    0    0  \n",
       "220      0    0    0    0    0    0    0  \n",
       "226      0    0    0    0    0    0    0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  \n",
       "98945    0    0    0    0    0    0    0  \n",
       "98959    0    0    0    0    0    0    0  \n",
       "98982    0    0    0    0    0    0    0  \n",
       "98996    0    0    0    0    0    0    0  \n",
       "99021    0    0    0    0    0    0    0  \n",
       "\n",
       "[3396 rows x 784 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_a = df_original[df_original.iloc[:, 0] == 1].drop(0, axis=1)\n",
    "df_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "091fad11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99032</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99033</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99035</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99036</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99037</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88800 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1    2    3    4    5    6    7    8    9    10   ...  775  776  777  \\\n",
       "0        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "1        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "4        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "99032    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "99033    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "99035    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "99036    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "99037    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "\n",
       "       778  779  780  781  782  783  784  \n",
       "0        0    0    0    0    0    0    0  \n",
       "1        0    0    0    0    0    0    0  \n",
       "2        0    0    0    0    0    0    0  \n",
       "3        0    0    0    0    0    0    0  \n",
       "4        0    0    0    0    0    0    0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  \n",
       "99032    0    0    0    0    0    0    0  \n",
       "99033    0    0    0    0    0    0    0  \n",
       "99035    0    0    0    0    0    0    0  \n",
       "99036    0    0    0    0    0    0    0  \n",
       "99037    0    0    0    0    0    0    0  \n",
       "\n",
       "[88800 rows x 784 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_without_blank = df_original[df_original.iloc[:, 0] != -1].drop(0, axis=1)\n",
    "df_without_blank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c6c450",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6735b0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMatrix(df):\n",
    "    arr = []\n",
    "\n",
    "    for row in range(len(df)):\n",
    "        img = df.iloc[row, :].values.reshape((28, 28))\n",
    "        arr.append(np.transpose(img))\n",
    "\n",
    "    arr = np.array(arr)\n",
    "    print(arr.shape)\n",
    "\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a908eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99040, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "imageArr = createMatrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "838ebd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3396, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "aArr = createMatrix(df_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03e19616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88800, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "withoutBlankArr = createMatrix(df_without_blank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998e2b37",
   "metadata": {},
   "source": [
    "# 3. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcc4dfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest pixel value: 255\n",
      "Lowest pixel value: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'Highest pixel value: {np.max(withoutBlankArr)}')\n",
    "print(f'Lowest pixel value: {np.min(withoutBlankArr)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7af9067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(img):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36cce34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_image(imageArr[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbce6bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageSubplot(arr, numberOfImages):\n",
    "    plt.figure()\n",
    "\n",
    "    for i in range(numberOfImages):\n",
    "        plt.subplot(numberOfImages // 3, 3, i+1)  \n",
    "        plt.imshow(arr[i], cmap='gray')\n",
    "        plt.axis('off')  \n",
    "\n",
    "    plt.tight_layout()  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6b30708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imageSubplot(imageArr, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cd2a719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imageSubplot(aArr, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e8d586f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(alphabets.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a732b182-3eb1-4eb7-aca9-8933d57a9db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alphabets.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e93b0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 10240\n",
      "1: 3396\n",
      "2: 3396\n",
      "3: 3419\n",
      "4: 3398\n",
      "5: 3437\n",
      "6: 3394\n",
      "7: 3385\n",
      "8: 3424\n",
      "9: 3428\n",
      "10: 3402\n",
      "11: 3438\n",
      "12: 3415\n",
      "13: 3402\n",
      "14: 3365\n",
      "15: 3408\n",
      "16: 3430\n",
      "17: 3435\n",
      "18: 3419\n",
      "19: 3392\n",
      "20: 3436\n",
      "21: 3419\n",
      "22: 3422\n",
      "23: 3423\n",
      "24: 3437\n",
      "25: 3453\n",
      "26: 3427\n"
     ]
    }
   ],
   "source": [
    "labels, counts = np.unique(alphabets, return_counts=True)\n",
    "for label, count in zip(labels, counts):\n",
    "    print(f'{label}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "172f0283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='0', ylabel='count'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=alphabets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db7e9874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='0', ylabel='count'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=alphabets[alphabets != -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0ecec7",
   "metadata": {},
   "source": [
    "# Model Training (With -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc1c81e",
   "metadata": {},
   "source": [
    "## Conv2DTranpose from Lab 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed969898",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN():\n",
    "    \n",
    "    # this is the function to build the generator neural network\n",
    "    def build_generator(self):\n",
    "        model = Sequential(name='Generator')\n",
    "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim)) # connect the input to dense layer\n",
    "        model.add(Reshape((7, 7, 128)))\n",
    "        # upsample from 7*7 to 14*14\n",
    "        model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        # upsample to 28x28\n",
    "        model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(self.channels, kernel_size=7, padding=\"same\", activation='sigmoid'))\n",
    "        model.summary()\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "        return Model(noise, img)  # the keras Model class groups layers into an object with training and inference features\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        model = Sequential(name='Discriminator')\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def __init__(self, rows, cols, channels, z = 100):\n",
    "        # Input shape\n",
    "        self.img_rows = rows  # generated image height\n",
    "        self.img_cols = cols  # generated image width\n",
    "        self.channels = channels  # generated image channel\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = z  # the input is 1-D vector of noise\n",
    "        # Reduce learning rate from 0.001 to 0.0002, and beta1 from 0.9 to 0.5, which can stablize training and reduce oscillation\n",
    "        optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "        # The generator takes noise as input and generates images\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "        # The combined model (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer)\n",
    "    \n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "        # Load the dataset\n",
    "        X_train = np.array(imageArr)\n",
    "        # Rescale 0 to 1\n",
    "        X_train = X_train / 255\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        for epoch in range(epochs):\n",
    "            # ---------------------\n",
    "            # Train Discriminator\n",
    "            # ---------------------\n",
    "            # Select a random half of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "            # Sample noise and generate a batch of new images\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            # Train the discriminator (it classify real images as 1 and generated images as 0)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            # Train the generator (it wants discriminator to predict generated images as 1)\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "            \n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch)\n",
    "    \n",
    "    def save_imgs(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        # gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        os.makedirs('generated_mnist', exist_ok=True)\n",
    "        fig.savefig(\"generated_mnist/dcgan_mnist_{:d}.png\".format(epoch))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e175a03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan = DCGAN(28,28,1)\n",
    "dcgan.train(epochs=5000, batch_size=256, save_interval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51edbf39",
   "metadata": {},
   "source": [
    "## Upsampling from Lab 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da4de4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN():\n",
    "    def __init__(self, rows, cols, channels, z = 10):\n",
    "        # Input shape\n",
    "        self.img_rows = rows\n",
    "        self.img_cols = cols\n",
    "        self.channels = channels\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = z\n",
    "\n",
    "        optimizer = Adam(0.0001, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((7, 7, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=256, save_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        X_train = np.array(imageArr)\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = X_train / 127.5 - 1.\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            # Sample noise and generate a batch of new images\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator (real classified as ones and generated as zeros)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Train the generator (wants discriminator to mistake images as real)\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch)\n",
    "\n",
    "    def save_imgs(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"dcgan_mnist_{:d}.png\".format(epoch))\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b70e91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan = DCGAN(28,28,1)\n",
    "dcgan.train(epochs=5000, batch_size=256, save_interval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8426fdb",
   "metadata": {},
   "source": [
    "## Editted Conv2DTranspose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1058edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN():\n",
    "    \n",
    "    # this is the function to build the generator neural network\n",
    "    def build_generator(self):\n",
    "        model = Sequential(name='Generator')\n",
    "        model.add(Dense(256 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((7, 7, 256)))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same'))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Conv2D(self.channels, kernel_size=7, padding=\"same\", activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "        return Model(noise, img)\n",
    "        \n",
    "    def build_discriminator(self):\n",
    "        model = Sequential(name='Discriminator')\n",
    "\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))  # Adjust dropout rate\n",
    "\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))  # Adjust dropout rate\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def __init__(self, rows, cols, channels, z = 100):\n",
    "        # Input shape\n",
    "        self.img_rows = rows  # generated image height\n",
    "        self.img_cols = cols  # generated image width\n",
    "        self.channels = channels  # generated image channel\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = z  # the input is 1-D vector of noise\n",
    "        # Reduce learning rate from 0.001 to 0.0002, and beta1 from 0.9 to 0.5, which can stablize training and reduce oscillation\n",
    "        optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "        # The generator takes noise as input and generates images\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "        # The combined model (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer)\n",
    "    \n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "        # Load the dataset\n",
    "        X_train = np.array(imageArr)\n",
    "        # Rescale 0 to 1\n",
    "        X_train = X_train / 255\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        for epoch in range(epochs):\n",
    "            # ---------------------\n",
    "            # Train Discriminator\n",
    "            # ---------------------\n",
    "            # Select a random half of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "            # Sample noise and generate a batch of new images\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            # Train the discriminator (it classify real images as 1 and generated images as 0)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            # Train the generator (it wants discriminator to predict generated images as 1)\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "            \n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch)\n",
    "    \n",
    "    def save_imgs(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        # gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        os.makedirs('generated_mnist', exist_ok=True)\n",
    "        fig.savefig(\"generated_mnist/dcgan_mnist_{:d}.png\".format(epoch))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3e7b3e",
   "metadata": {},
   "source": [
    "# Model Training (Without -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbec3cf2",
   "metadata": {},
   "source": [
    "## machinelearningmastery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3069e141",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN:\n",
    "    def __init__(self, rows, cols, channels, z=100):\n",
    "        # Input shape\n",
    "        self.img_rows = rows  # generated image height\n",
    "        self.img_cols = cols  # generated image width\n",
    "        self.channels = channels  # generated image channel\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = z  # the input is 1-D vector of noise\n",
    "        # Reduce learning rate from 0.001 to 0.0002, and beta1 from 0.9 to 0.5, which can stabilize training and reduce oscillation\n",
    "        disc_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "        gen_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "                                   optimizer=disc_optimizer,\n",
    "                                   metrics=['accuracy'])\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "        # The generator takes noise as input and generates images\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "        # The combined model (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy',\n",
    "                              optimizer=gen_optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "        model = Sequential(name='Generator')\n",
    "        model.add(Dense(256 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim)) # connect the input to dense layer\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "        model.add(Reshape((7, 7, 256)))\n",
    "        # upsample from 7*7 to 14*14\n",
    "        model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "        # upsample to 28x28\n",
    "        model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "        model.add(Conv2D(self.channels, (3,3), padding=\"same\", activation='tanh'))\n",
    "        model.summary()\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "        return Model(noise, img)  # the keras Model class groups layers into an object with training and inference features\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        model = Sequential(name='Discriminator')\n",
    "        # normal\n",
    "        model.add(Conv2D(128, (3,3), padding='same', input_shape=self.img_shape))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.4))\n",
    "        # downsample\n",
    "        model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.4))\n",
    "        # classifier\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "        # scale to [-1, 1]\n",
    "        X_train = withoutBlankArr / 127.5 - 1\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        # Lists to store the losses\n",
    "        d_losses = []\n",
    "        g_losses = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # ---------------------\n",
    "            # Train Discriminator\n",
    "            # ---------------------\n",
    "            # Select a random half of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "            # Sample noise and generate a batch of new images\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            # Train the discriminator (it classify real images as 1 and generated images as 0)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            d_losses.append(d_loss[0])  # Record the discriminator loss\n",
    "\n",
    "            # ---------------------\n",
    "            # Train Generator\n",
    "            # ---------------------\n",
    "            # Train the generator (it wants discriminator to predict generated images as 1)\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "            g_losses.append(g_loss)  # Record the generator loss\n",
    "\n",
    "            # Plot the progress\n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch)\n",
    "\n",
    "        # Plot loss curves\n",
    "        self.plot_loss(d_losses, g_losses)\n",
    "\n",
    "    def save_imgs(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        # gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        os.makedirs('generated_mnist', exist_ok=True)\n",
    "        fig.savefig(\"generated_mnist/dcgan_mnist_{:d}.png\".format(epoch))\n",
    "        plt.close()\n",
    "\n",
    "    def plot_loss(self, d_losses, g_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(d_losses, label='Discriminator Loss')\n",
    "        plt.plot(g_losses, label='Generator Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Loss Curves')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995b54e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan = DCGAN(28,28,1)\n",
    "dcgan.train(epochs=5000, batch_size=256, save_interval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78051de5",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2fefa7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_388 (Conv2D)         (None, 6, 6, 64)          640       \n",
      "                                                                 \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 6, 6, 64)          0         \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 6, 6, 64)          0         \n",
      "                                                                 \n",
      " conv2d_389 (Conv2D)         (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 3, 3, 128)         0         \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 3, 3, 128)         0         \n",
      "                                                                 \n",
      " conv2d_390 (Conv2D)         (None, 2, 2, 128)         147584    \n",
      "                                                                 \n",
      " leaky_re_lu_14 (LeakyReLU)  (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 222,593\n",
      "Trainable params: 222,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"Generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 12544)             1254400   \n",
      "                                                                 \n",
      " batch_normalization_396 (Ba  (None, 12544)            50176     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_20 (ReLU)             (None, 12544)             0         \n",
      "                                                                 \n",
      " reshape_4 (Reshape)         (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_20 (Conv2D  (None, 14, 14, 128)      32768     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_397 (Ba  (None, 14, 14, 128)      512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_21 (ReLU)             (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_21 (Conv2D  (None, 14, 14, 128)      147456    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_398 (Ba  (None, 14, 14, 128)      512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_22 (ReLU)             (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_22 (Conv2D  (None, 14, 14, 128)      147456    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_399 (Ba  (None, 14, 14, 128)      512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_23 (ReLU)             (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_23 (Conv2D  (None, 28, 28, 128)      409600    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_400 (Ba  (None, 28, 28, 128)      512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_24 (ReLU)             (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_24 (Conv2D  (None, 28, 28, 1)        1152      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,045,056\n",
      "Trainable params: 2,018,944\n",
      "Non-trainable params: 26,112\n",
      "_________________________________________________________________\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 1s 39ms/step\n",
      "8/8 [==============================] - 0s 35ms/step\n",
      "0 [D loss: 0.6898413598537445, acc.: 39.26%] [G loss: 0.6969302296638489] [FID: 14.01323942771186]\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 38ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "50 [D loss: 0.6892173588275909, acc.: 33.01%] [G loss: 0.5976380705833435] [FID: 10.729851834896646]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 39ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "100 [D loss: 0.6905370056629181, acc.: 40.62%] [G loss: 0.5652801990509033] [FID: 9.350990327702359]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 37ms/step\n",
      "8/8 [==============================] - 0s 35ms/step\n",
      "150 [D loss: 0.696030855178833, acc.: 46.68%] [G loss: 0.5419575572013855] [FID: 12.1644979348155]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 37ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "200 [D loss: 0.7128052413463593, acc.: 47.07%] [G loss: 0.5255443453788757] [FID: 21.311864932457826]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 37ms/step\n",
      "8/8 [==============================] - 0s 35ms/step\n",
      "250 [D loss: 0.7365243136882782, acc.: 47.46%] [G loss: 0.5278394222259521] [FID: 65.77250252744331]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 38ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "300 [D loss: 0.7500194311141968, acc.: 48.83%] [G loss: 0.5356301069259644] [FID: 88.432670035184]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 38ms/step\n",
      "8/8 [==============================] - 0s 35ms/step\n",
      "350 [D loss: 0.7549814283847809, acc.: 48.24%] [G loss: 0.5391063094139099] [FID: 105.9472061274294]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 38ms/step\n",
      "8/8 [==============================] - 0s 35ms/step\n",
      "400 [D loss: 0.7521811425685883, acc.: 48.05%] [G loss: 0.5537924766540527] [FID: 145.60537939141778]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 38ms/step\n",
      "450 [D loss: 0.7439495921134949, acc.: 47.27%] [G loss: 0.5680787563323975] [FID: 190.6916795020217]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 39ms/step\n",
      "8/8 [==============================] - 0s 38ms/step\n",
      "500 [D loss: 0.7358441054821014, acc.: 48.44%] [G loss: 0.580256998538971] [FID: 206.69979288204544]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 37ms/step\n",
      "550 [D loss: 0.7345328629016876, acc.: 49.02%] [G loss: 0.5859101414680481] [FID: 185.54477735239723]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 39ms/step\n",
      "600 [D loss: 0.7300291061401367, acc.: 48.83%] [G loss: 0.5934664011001587] [FID: 203.3250677865652]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 39ms/step\n",
      "8/8 [==============================] - 0s 35ms/step\n",
      "650 [D loss: 0.7177295982837677, acc.: 49.41%] [G loss: 0.6057562232017517] [FID: 197.7869062518398]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "700 [D loss: 0.7255015075206757, acc.: 48.44%] [G loss: 0.5949317812919617] [FID: 152.8435878407669]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 38ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "750 [D loss: 0.7192111611366272, acc.: 49.41%] [G loss: 0.6034749746322632] [FID: 180.7767418907614]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 39ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "800 [D loss: 0.7202550768852234, acc.: 49.02%] [G loss: 0.605726420879364] [FID: 153.36310722237067]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 41ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "850 [D loss: 0.7109021544456482, acc.: 48.44%] [G loss: 0.6188719272613525] [FID: 147.7753241314579]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 39ms/step\n",
      "8/8 [==============================] - 0s 35ms/step\n",
      "900 [D loss: 0.7112038135528564, acc.: 48.24%] [G loss: 0.6166191101074219] [FID: 202.9478527315859]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "950 [D loss: 0.7190501391887665, acc.: 48.83%] [G loss: 0.606951117515564] [FID: 161.29661491368046]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 41ms/step\n",
      "8/8 [==============================] - 0s 39ms/step\n",
      "1000 [D loss: 0.721270889043808, acc.: 48.24%] [G loss: 0.6045732498168945] [FID: 167.34230108065304]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 38ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "1050 [D loss: 0.7188840508460999, acc.: 48.63%] [G loss: 0.6079854369163513] [FID: 188.32828704420967]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 43ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "1100 [D loss: 0.7201072871685028, acc.: 48.83%] [G loss: 0.6111900806427002] [FID: 183.70870032178738]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 38ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "1150 [D loss: 0.7159701585769653, acc.: 48.05%] [G loss: 0.6128367185592651] [FID: 157.08699493472506]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 38ms/step\n",
      "8/8 [==============================] - 0s 36ms/step\n",
      "1200 [D loss: 0.7116234600543976, acc.: 48.63%] [G loss: 0.6236914396286011] [FID: 147.89821002428906]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20252\\2145597851.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReLU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2DTranspose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLeakyReLU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20252\\2145597851.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, epochs, batch_size, save_interval)\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[0mg_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Record the generator loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m             \u001b[1;31m# Calculate FID score at intervals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msave_interval\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minception_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_imgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m                 \u001b[0mfid_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{epoch} [D loss: {d_loss[0]}, acc.: {100 * d_loss[1]:.2f}%] [G loss: {g_loss}] [FID: {fid}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_imgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20252\\2145597851.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, model, real_images, generated_images)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcalculate_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerated_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;31m# Resize images to (299, 299) and convert grayscale to RGB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0mreal_images_resized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess_for_inception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[0mgenerated_images_resized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess_for_inception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;31m# Get the activations from the InceptionV3 model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mact_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_images_resized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20252\\2145597851.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, images)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mimages_rgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[1;31m# Convert grayscale to RGB by repeating the single channel three times\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0mimg_rgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m             \u001b[0mimg_resized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_rgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m299\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m299\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m             \u001b[0mimg_resized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_resized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[0mimages_rgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_resized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mimages_rgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages_rgb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\p2309248\\.conda\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\p2309248\\.conda\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1180\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1181\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\p2309248\\.conda\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(images, size, method, preserve_aspect_ratio, antialias, name)\u001b[0m\n\u001b[0;32m   1762\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mresize_with_scale_and_translate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1763\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1764\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Resize method is not implemented: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1766\u001b[1;33m   return _resize_images_common(\n\u001b[0m\u001b[0;32m   1767\u001b[0m       \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1768\u001b[0m       \u001b[0mresize_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1769\u001b[0m       \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\p2309248\\.conda\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(images, resizer_fn, size, preserve_aspect_ratio, name, skip_resize_if_same)\u001b[0m\n\u001b[0;32m   1503\u001b[0m     \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_height_const\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_width_const\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1505\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_batch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1506\u001b[0m       \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1507\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\p2309248\\.conda\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\p2309248\\.conda\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1180\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1181\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\p2309248\\.conda\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    557\u001b[0m                 \u001b[0m_call_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorator_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_qualified_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m                 instructions)\n\u001b[1;32m--> 561\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\p2309248\\.conda\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(input, axis, name, dim)\u001b[0m\n\u001b[0;32m    368\u001b[0m   \"\"\"\n\u001b[0;32m    369\u001b[0m   \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeprecation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeprecated_argument_lookup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"axis\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dim\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Must specify an axis argument to tf.expand_dims()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 372\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mexpand_dims_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\p2309248\\.conda\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\p2309248\\.conda\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1180\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1181\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\p2309248\\.conda\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(input, axis, name)\u001b[0m\n\u001b[0;32m    438\u001b[0m   \u001b[0mRaises\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mspecified\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[0mInvalidArgumentError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mout\u001b[0m \u001b[0mof\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m]\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m   \"\"\"\n\u001b[1;32m--> 442\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\p2309248\\.conda\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(input, axis, name)\u001b[0m\n\u001b[0;32m   2346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2347\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2348\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2349\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2350\u001b[1;33m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2351\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2352\u001b[0m       return expand_dims_eager_fallback(\n\u001b[0;32m   2353\u001b[0m           input, axis, name=name, ctx=_ctx)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, ReLU, Reshape, Conv2DTranspose, Conv2D, LeakyReLU, Dropout, Flatten, Input\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.linalg import sqrtm\n",
    "import tensorflow as tf\n",
    "\n",
    "class DCGAN:\n",
    "    def __init__(self, rows, cols, channels, z=100):\n",
    "        # Input shape\n",
    "        self.img_rows = rows\n",
    "        self.img_cols = cols\n",
    "        self.channels = channels\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = z\n",
    "        disc_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "        gen_optimizer = Adam(learning_rate=0.0001, beta_1=0.5)\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "                                   optimizer=disc_optimizer,\n",
    "                                   metrics=['accuracy'])\n",
    "        self.generator = self.build_generator()\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "        self.discriminator.trainable = False\n",
    "        valid = self.discriminator(img)\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy',\n",
    "                              optimizer=gen_optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "        model = Sequential(name='Generator')\n",
    "        model.add(Dense(7*7*256, use_bias=False, input_dim=self.latent_dim))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "        model.add(Reshape((7, 7, 256)))\n",
    "\n",
    "        model.add(Conv2DTranspose(128, (1, 1), strides=(2, 2), padding='same', use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "\n",
    "        model.add(Conv2DTranspose(128, (3, 3), strides=(1, 1), padding='same', use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "\n",
    "        model.add(Conv2DTranspose(128, (3, 3), strides=(1, 1), padding='same', use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "\n",
    "        model.add(Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "\n",
    "        model.add(Conv2DTranspose(1, (3, 3), strides=(1, 1), padding='same', use_bias=False, activation='tanh'))\n",
    "        model.summary()\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        model = Sequential(name='Discriminator')\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=5, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        \n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def preprocess_for_inception(self, images):\n",
    "        images_rgb = []\n",
    "        for img in images:\n",
    "            # Convert grayscale to RGB by repeating the single channel three times\n",
    "            img_rgb = np.repeat(img, 3, axis=-1)\n",
    "            img_resized = tf.image.resize(img_rgb, (299, 299))\n",
    "            img_resized = img_to_array(img_resized)\n",
    "            images_rgb.append(img_resized)\n",
    "        images_rgb = np.array(images_rgb)\n",
    "        return preprocess_input(images_rgb)\n",
    "\n",
    "    def calculate_fid(self, model, real_images, generated_images):\n",
    "        # Resize images to (299, 299) and convert grayscale to RGB\n",
    "        real_images_resized = self.preprocess_for_inception(real_images)\n",
    "        generated_images_resized = self.preprocess_for_inception(generated_images)\n",
    "        # Get the activations from the InceptionV3 model\n",
    "        act_real = model.predict(real_images_resized)\n",
    "        act_gen = model.predict(generated_images_resized)\n",
    "        # Calculate the mean and covariance of the activations\n",
    "        mu_real, sigma_real = act_real.mean(axis=0), np.cov(act_real, rowvar=False)\n",
    "        mu_gen, sigma_gen = act_gen.mean(axis=0), np.cov(act_gen, rowvar=False)\n",
    "        # Calculate the sum of squared differences between means\n",
    "        ssdiff = np.sum((mu_real - mu_gen) ** 2.0)\n",
    "        # Calculate the square root of the product of the covariances\n",
    "        covmean = sqrtm(sigma_real.dot(sigma_gen))\n",
    "        # Handle imaginary numbers\n",
    "        if np.iscomplexobj(covmean):\n",
    "            covmean = covmean.real\n",
    "        # Calculate the FID score\n",
    "        fid = ssdiff + np.trace(sigma_real + sigma_gen - 2.0 * covmean)\n",
    "        return fid\n",
    "\n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "        inception_model = InceptionV3(include_top=False, pooling='avg', input_shape=(299, 299, 3))\n",
    "\n",
    "        # scale to [-1, 1]\n",
    "        X_train = (withoutBlankArr - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        # Lists to store the losses and FID scores\n",
    "        d_losses = []\n",
    "        g_losses = []\n",
    "        fid_scores = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # ---------------------\n",
    "            # Train Discriminator\n",
    "            # ---------------------\n",
    "            # Select a random half of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "            # Sample noise and generate a batch of new images\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            # Train the discriminator (it classify real images as 1 and generated images as 0)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            d_losses.append(d_loss[0])  # Record the discriminator loss\n",
    "\n",
    "            # ---------------------\n",
    "            # Train Generator\n",
    "            # ---------------------\n",
    "            # Train the generator (it wants discriminator to predict generated images as 1)\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "            g_losses.append(g_loss)  # Record the generator loss\n",
    "\n",
    "            # Calculate FID score at intervals\n",
    "            if epoch % save_interval == 0:\n",
    "                fid = self.calculate_fid(inception_model, imgs, gen_imgs)\n",
    "                fid_scores.append(fid)\n",
    "                print(f\"{epoch} [D loss: {d_loss[0]}, acc.: {100 * d_loss[1]:.2f}%] [G loss: {g_loss}] [FID: {fid}]\")\n",
    "                self.save_imgs(epoch)\n",
    "\n",
    "        # Plot loss curves and FID scores\n",
    "        self.plot_loss(d_losses, g_losses, fid_scores)\n",
    "\n",
    "    def save_imgs(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        if not os.path.exists('images'):\n",
    "            os.makedirs('images')\n",
    "        fig.savefig(f\"images/mnist_{epoch}.png\")\n",
    "        plt.close()\n",
    "\n",
    "    def plot_loss(self, d_losses, g_losses, fid_scores):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(d_losses, label=\"Discriminator loss\")\n",
    "        plt.plot(g_losses, label=\"Generator loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot([i*50 for i in range(len(fid_scores))], fid_scores, label=\"FID score\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"FID score\")\n",
    "        plt.legend()\n",
    "\n",
    "        if not os.path.exists('plots'):\n",
    "            os.makedirs('plots')\n",
    "        plt.savefig(\"plots/loss_fid.png\")\n",
    "        plt.show()\n",
    "\n",
    "# Ensure your training dataset withoutBlankArr is properly loaded here\n",
    "\n",
    "dcgan = DCGAN(28, 28, 1)\n",
    "dcgan.train(epochs=10001, batch_size=256, save_interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f96c04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.19 ('gpu_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "5b460c8134041a9eb7f811dfdfca680bf522aea7d6535220209a5df6379dc02a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
